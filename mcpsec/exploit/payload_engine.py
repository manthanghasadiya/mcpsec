"""
Payload recommendation engine that combines static playbooks and AI logic.
"""
from typing import List, Optional, Any
import json
from mcpsec.models import ToolInfo
from .state_tracker import ExploitState
from .playbooks import PLAYBOOKS, Playbook, ExploitStage, PayloadEntry

class PayloadEngine:
    def __init__(self, use_ai: bool = False):
        self.use_ai = use_ai
        self.ai_client = None
        if self.use_ai:
            from mcpsec.ai.llm_client import LLMClient
            try:
                self.ai_client = LLMClient()
            except Exception:
                self.use_ai = False

    def get_playbook(self, state: ExploitState) -> Playbook:
        """Retrieves the appropriate playbook based on the finding's scanner."""
        if not state.finding:
            return PLAYBOOKS["generic"]
            
        vuln_type = state.finding.scanner.replace("ai-", "").lower()
        if vuln_type not in PLAYBOOKS:
            # Map common names
            if "sql" in vuln_type.lower():
                vuln_type = "sqli"
            elif "rce" in vuln_type.lower() or "command" in vuln_type.lower():
                vuln_type = "command_injection"
            elif "path" in vuln_type.lower() or "traversal" in vuln_type.lower():
                vuln_type = "path_traversal"
            else:
                vuln_type = "generic"
                
        return PLAYBOOKS.get(vuln_type, PLAYBOOKS["generic"])

    async def suggest_payloads(self, state: ExploitState, tool: ToolInfo) -> List[PayloadEntry]:
        """Suggests next payloads based on current state and playbook."""
        playbook = self.get_playbook(state)
        
        # Find the current stage
        current_stage = next((s for s in playbook.stages if s.name == state.stage), playbook.stages[0])
        
        static_payloads = current_stage.payloads
        
        if self.use_ai and self.ai_client:
            ai_payloads = await self._get_ai_recommendations(state, tool, current_stage)
            # Prepend AI payloads so they show up vividly or just return them all
            return static_payloads + ai_payloads
            
        return static_payloads

    async def _get_ai_recommendations(self, state: ExploitState, tool: ToolInfo, current_stage: ExploitStage) -> List[PayloadEntry]:
        """Queries the AI client for intelligent payload recommendations."""
        
        finding_info = "Manual Exploration"
        if state.finding:
            finding_info = (f"Type: {state.finding.scanner}\\n"
                            f"Tool: {state.finding.tool_name}\\n"
                            f"Parameter: {state.finding.parameter}\\n"
                            f"Original Details: {state.finding.description}")

        attempts_log = ""
        for i, a in enumerate(state.attempts):
            success = "SUCCESS" if a.success else "FAILED"
            attempts_log += f"Attempt {i+1}:\\nPayload: {json.dumps(a.payload)}\\nResult: ({success}) {str(a.response)[:200]}\\n\\n"

        prompt = f"""You are an MCP security exploitation copilot helping validate and exploit a finding.

SERVER CONTEXT:
- Target: {state.target}
- Available Tool: {tool.name}
- Parameters: {json.dumps(tool.raw_schema)}

FINDING:
{finding_info}

EXPLOITATION STATE:
- Stage: {current_stage.name} - {current_stage.description}
- AI Escalation Prompt: {current_stage.ai_escalation_prompt}
- Attempts so far:
{attempts_log if attempts_log else 'No prior attempts.'}

- Server Behavior Learned: {json.dumps(state.server_behavior)}

TASK:
Recommend exactly 3 intelligent payloads for the next step.
Return your answer strictly as a JSON array of objects, with each object containing:
- "payload": The specific value to inject (use as raw primitive or object as expected by parameter).
- "description": A short, scannable one-line explanation of what it tests and aims to achieve.
Example Output:
[ {{"payload": "../../etc/passwd", "description": "Tests basic traversal."}}, ... ]
"""

        try:
            response = await self.ai_client.generate(
                prompt=prompt,
                system="You are a penetration testing tool. Output ONLY pure JSON array without markdown formatting.",
                temperature=0.4
            )
            
            # Clean possible markdown block
            text = response.text.strip()
            if text.startswith("```json"):
                text = text[7:-3].strip()
            elif text.startswith("```"):
                text = text[3:-3].strip()
                
            data = json.loads(text)
            
            results = []
            for item in data:
                # the payload from AI is mapping to the vulnerable parameter. 
                # Our PayloadEntry expects just the value, not the fully formed argument dict yet.
                results.append(PayloadEntry(
                    payload=item.get("payload", ""),
                    description=f"[AI] {item.get('description', 'AI Suggested')}"
                ))
            return results
        except Exception as e:
            # On generic errors, fallback strictly to static
            return []

    # ─── New AI Exploitation Methods ─────────────────────────────────────────

    async def generate_initial_payloads(self, state: ExploitState, tool: ToolInfo) -> List[PayloadEntry]:
        """Generate first round of payloads based on finding context."""
        if not self.use_ai or not self.ai_client:
            # Fallback to static playbook
            playbook = self.get_playbook(state)
            return playbook.stages[0].payloads[:5]

        finding = state.finding
        evidence_str = finding.evidence if finding and finding.evidence else "N/A"
        description_str = finding.description if finding else "N/A"

        prompt = f"""You are an expert penetration tester analyzing an MCP server vulnerability finding.

FINDING DETAILS:
- Type: {finding.scanner if finding else 'unknown'}
- Tool: {finding.tool_name if finding else 'unknown'}
- Vulnerable Parameter: {finding.parameter if finding else 'unknown'}
- Scanner Evidence: {description_str}
- Raw Evidence: {evidence_str[:500]}

TOOL SCHEMA:
{json.dumps(tool.raw_schema, indent=2)}

TASK:
Generate exactly 5 targeted payloads to confirm or deny this vulnerability.
- Start with variations of the original payload that triggered the finding
- Include both subtle and aggressive payloads
- Consider common bypasses and encoding tricks

Return ONLY a JSON array:
[
  {{"payload": "<value>", "description": "<what this tests>"}},
  ...
]
"""
        return await self._call_ai_for_payloads(prompt)

    async def generate_next_payloads(self, state: ExploitState, tool: ToolInfo, history: List[dict]) -> List[PayloadEntry]:
        """Generate next round of payloads based on learned behavior."""
        if not self.use_ai or not self.ai_client:
            return []

        # Build history summary
        history_text = ""
        for i, h in enumerate(history[-10:]):  # Last 10 attempts
            history_text += (
                f"\nAttempt {i+1}:\n"
                f"  Payload: {h['payload']}\n"
                f"  Response: {str(h['response'])[:200]}\n"
                f"  Success: {h['success']}\n"
            )

        finding = state.finding
        prompt = f"""You are an expert penetration tester in an active exploitation session.

FINDING:
- Type: {finding.scanner if finding else 'unknown'}
- Tool: {finding.tool_name if finding else 'unknown'}
- Parameter: {finding.parameter if finding else 'unknown'}

PREVIOUS ATTEMPTS:
{history_text}

LEARNED BEHAVIORS:
{json.dumps(state.server_behavior)}

TASK:
Based on the server's responses, generate 3 NEW payloads that:
1. Learn from what worked/failed
2. Try different bypass techniques
3. Attempt to escalate impact

If you believe further testing is pointless (definite false positive OR already confirmed), return an empty array [].

Return ONLY a JSON array:
[
  {{"payload": "<value>", "description": "<what this tests and why based on previous responses>"}},
  ...
]
"""
        return await self._call_ai_for_payloads(prompt)

    async def render_verdict(self, state: ExploitState, history: List[dict]) -> dict:
        """AI analyzes all attempts and renders final verdict."""
        if not self.use_ai or not self.ai_client:
            return {
                "verdict": "UNKNOWN",
                "reason": "AI not available for verdict"
            }

        # Build complete history
        history_text = ""
        for i, h in enumerate(history):
            history_text += (
                f"\nAttempt {i+1}:\n"
                f"  Payload: {h['payload']}\n"
                f"  Response: {str(h['response'])[:300]}\n"
            )

        finding = state.finding
        prompt = f"""You are a senior penetration tester reviewing exploitation attempts.

ORIGINAL FINDING:
- Type: {finding.scanner if finding else 'unknown'}
- Tool: {finding.tool_name if finding else 'unknown'}
- Parameter: {finding.parameter if finding else 'unknown'}
- Scanner Evidence: {finding.description if finding else 'N/A'}

ALL EXPLOITATION ATTEMPTS:
{history_text}

TASK:
Analyze all attempts and render a final verdict.

Consider:
- Did any payload demonstrate actual exploitation (data leak, error disclosure, behavioral change)?
- Are the "vulnerable" responses just normal error handling?
- Is there concrete evidence of the vulnerability being real?

Return ONLY a JSON object:
{{
  "verdict": "CONFIRMED" or "FALSE_POSITIVE",
  "reason": "<detailed explanation with specific evidence from the attempts>",
  "severity_assessment": "<if confirmed, assess actual severity based on demonstrated impact>",
  "recommended_next_steps": "<what should the tester do next>"
}}
"""
        try:
            response_text = await self.ai_client.chat(
                system="You are a penetration testing verdict engine. Be conservative - only CONFIRM if there's clear evidence. Output ONLY valid JSON.",
                user=prompt,
                temperature=0.2
            )

            if not response_text:
                return {"verdict": "UNKNOWN", "reason": "AI returned empty response"}

            text = response_text.strip()
            if text.startswith("```"):
                text = text.split("```")[1]
                if text.startswith("json"):
                    text = text[4:]

            return json.loads(text)
        except Exception as e:
            return {
                "verdict": "UNKNOWN",
                "reason": f"AI error: {str(e)}"
            }

    async def _call_ai_for_payloads(self, prompt: str) -> List[PayloadEntry]:
        """Helper to call AI and parse payload responses."""
        try:
            response_text = await self.ai_client.chat(
                system="You are a penetration testing payload generator. Output ONLY pure JSON array without markdown.",
                user=prompt,
                temperature=0.4
            )

            if not response_text:
                return []

            text = response_text.strip()
            if text.startswith("```json"):
                text = text[7:-3].strip()
            elif text.startswith("```"):
                text = text[3:-3].strip()

            data = json.loads(text)

            results = []
            for item in data:
                results.append(PayloadEntry(
                    payload=item.get("payload", ""),
                    description=f"[AI] {item.get('description', 'AI Suggested')}"
                ))
            return results
        except Exception:
            return []

    def _format_history(self, history: List[dict]) -> str:
        """Helper to format attempt history for prompts."""
        if not history:
            return "No prior attempts."

        text = ""
        for i, h in enumerate(history[-10:]):
            manual = " [MANUAL]" if h.get("manual") else ""
            text += (
                f"\nAttempt {i+1}{manual}:\n"
                f"  Payload: {h['payload']}\n"
                f"  Response: {str(h['response'])[:200]}\n"
            )
        return text

    async def generate_aggressive_payloads(self, state: ExploitState, tool: ToolInfo, history: List[dict]) -> List[PayloadEntry]:
        """Generate aggressive bypass payloads after initial attempts failed."""
        if not self.use_ai or not self.ai_client:
            return []

        history_text = self._format_history(history)
        finding = state.finding

        prompt = f"""You are an expert penetration tester. Previous standard payloads were marked as FALSE POSITIVE.
The user wants you to try HARDER with advanced bypass techniques.

FINDING:
- Type: {finding.scanner if finding else 'unknown'}
- Tool: {finding.tool_name if finding else 'unknown'}
- Parameter: {finding.parameter if finding else 'unknown'}

PREVIOUS ATTEMPTS (all failed to confirm):
{history_text}

TASK:
Generate 5 AGGRESSIVE payloads using advanced techniques:
- Encoding bypasses (URL, double-URL, Unicode, hex)
- Comment insertion (/**/, --%0a, #)
- Case variation and null bytes
- WAF/filter bypass patterns
- Alternative syntax for same operation
- Time-based blind techniques
- Out-of-band techniques (if applicable)

Think like a CTF player trying to bypass filters. Be creative.

Return ONLY a JSON array:
[
  {{"payload": "<value>", "description": "<bypass technique used>"}},
  ...
]
"""
        return await self._call_ai_for_payloads(prompt)

    async def generate_hinted_payloads(self, state: ExploitState, tool: ToolInfo, history: List[dict], hint: str) -> List[PayloadEntry]:
        """Generate payloads based on user's specific hint."""
        if not self.use_ai or not self.ai_client:
            return []

        history_text = self._format_history(history)
        finding = state.finding

        prompt = f"""You are an expert penetration tester receiving guidance from a senior tester.

FINDING:
- Type: {finding.scanner if finding else 'unknown'}
- Tool: {finding.tool_name if finding else 'unknown'}
- Parameter: {finding.parameter if finding else 'unknown'}

PREVIOUS ATTEMPTS:
{history_text}

USER HINT:
"{hint}"

TASK:
Generate 3 payloads specifically following the user's hint direction.
The user is experienced - trust their intuition and create targeted payloads.

Return ONLY a JSON array:
[
  {{"payload": "<value>", "description": "<how this follows the hint>"}},
  ...
]
"""
        return await self._call_ai_for_payloads(prompt)
