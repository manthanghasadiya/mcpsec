"""Tests for the exploit session and AI exploitation features."""
import pytest
import json
import tempfile
import os

from mcpsec.models import Finding, Severity, ScanResult, TransportType, ServerProfile, ToolInfo


# ─── Finding model tests ────────────────────────────────────────────────────

def test_finding_parameter_field():
    """Finding model should accept and store the parameter field."""
    f = Finding(
        severity=Severity.HIGH,
        scanner="sql-rce",
        title="SQL Injection in write_query",
        tool_name="write_query",
        parameter="query",
    )
    assert f.parameter == "query"
    assert f.tool_name == "write_query"


def test_finding_parameter_default_empty():
    """Finding.parameter should default to empty string."""
    f = Finding(severity=Severity.LOW, scanner="test", title="Test")
    assert f.parameter == ""


# ─── --from-scan parsing tests ──────────────────────────────────────────────

def test_from_scan_raw_array():
    """--from-scan should parse a raw JSON array of findings."""
    findings_data = [
        {
            "severity": "high",
            "scanner": "command-injection",
            "title": "Command Injection in run_command",
            "tool_name": "run_command",
            "parameter": "cmd",
        },
        {
            "severity": "medium",
            "scanner": "path-traversal",
            "title": "Path Traversal in read_file",
            "tool_name": "read_file",
            "parameter": "path",
        },
    ]

    with tempfile.NamedTemporaryFile(mode="w", suffix=".json", delete=False) as f:
        json.dump(findings_data, f)
        tmp_path = f.name

    try:
        with open(tmp_path, "r") as f:
            data = json.load(f)

        assert isinstance(data, list)
        findings = [Finding.model_validate(item) for item in data]
        assert len(findings) == 2
        assert findings[0].parameter == "cmd"
        assert findings[1].scanner == "path-traversal"
    finally:
        os.unlink(tmp_path)


def test_from_scan_scan_result_wrapper():
    """--from-scan should parse a ScanResult JSON wrapper."""
    scan_data = {
        "scan_id": "test-123",
        "target": "python my_server.py",
        "transport": "stdio",
        "findings": [
            {
                "severity": "critical",
                "scanner": "sqli",
                "title": "SQL Injection",
                "tool_name": "query_db",
                "parameter": "sql",
            }
        ],
        "scanners_run": ["sqli"],
    }

    with tempfile.NamedTemporaryFile(mode="w", suffix=".json", delete=False) as f:
        json.dump(scan_data, f)
        tmp_path = f.name

    try:
        with open(tmp_path, "r") as f:
            data = json.load(f)

        assert isinstance(data, dict)
        assert "findings" in data
        sr = ScanResult.model_validate(data)
        assert len(sr.findings) == 1
        assert sr.findings[0].parameter == "sql"
    finally:
        os.unlink(tmp_path)


def test_from_scan_dict_with_findings_key():
    """--from-scan should handle a dict with 'findings' key that isn't a full ScanResult."""
    partial_data = {
        "findings": [
            {
                "severity": "high",
                "scanner": "ssrf",
                "title": "SSRF in fetch",
                "tool_name": "fetch_url",
                "parameter": "url",
            }
        ]
    }

    with tempfile.NamedTemporaryFile(mode="w", suffix=".json", delete=False) as f:
        json.dump(partial_data, f)
        tmp_path = f.name

    try:
        with open(tmp_path, "r") as f:
            data = json.load(f)

        # Should try ScanResult first, then fall back to raw findings parsing
        if isinstance(data, dict) and "findings" in data:
            try:
                sr = ScanResult.model_validate(data)
                findings = sr.findings
            except Exception:
                findings = [Finding.model_validate(item) for item in data["findings"]]
        
        assert len(findings) == 1
        assert findings[0].parameter == "url"
    finally:
        os.unlink(tmp_path)


# ─── ExploitSession init tests ──────────────────────────────────────────────

def test_exploit_session_init_state():
    """ExploitSession should initialize all new AI exploitation state fields."""
    from mcpsec.exploit.session import ExploitSession

    try:
        session = ExploitSession(
            target="python test.py",
            transport=TransportType.STDIO,
            findings=[],
            use_ai=False,
        )
    except Exception as e:
        # prompt_toolkit can't init without a real console (NoConsoleScreenBufferError)
        if "ConsoleScreenBuffer" in str(type(e).__name__) or "NoConsole" in str(e):
            pytest.skip("No console available for prompt_toolkit")
        raise

    assert session.current_suggestions == []
    assert session.suggestion_history == []
    assert session.ai_verdict is None
    assert session.ai_verdict_reason == ""
    assert session.exploitation_mode is False


def test_exploit_session_init_with_findings():
    """ExploitSession should store findings from constructor."""
    from mcpsec.exploit.session import ExploitSession

    findings = [
        Finding(severity=Severity.HIGH, scanner="test", title="Finding 1", tool_name="tool_a", parameter="p1"),
        Finding(severity=Severity.MEDIUM, scanner="test", title="Finding 2", tool_name="tool_b", parameter="p2"),
    ]

    try:
        session = ExploitSession(
            target="python test.py",
            transport=TransportType.STDIO,
            findings=findings,
            use_ai=False,  # Don't require AI module for this test
        )
    except Exception as e:
        if "ConsoleScreenBuffer" in str(type(e).__name__) or "NoConsole" in str(e):
            pytest.skip("No console available for prompt_toolkit")
        raise

    assert len(session.findings) == 2
    assert session.findings[0].parameter == "p1"


# ─── PayloadEngine fallback tests ───────────────────────────────────────────

@pytest.mark.asyncio
async def test_payload_engine_fallback_without_ai():
    """generate_initial_payloads should fall back to static playbook when AI is off."""
    from mcpsec.exploit.payload_engine import PayloadEngine
    from mcpsec.exploit.state_tracker import ExploitState

    engine = PayloadEngine(use_ai=False)
    state = ExploitState(
        finding=Finding(
            severity=Severity.HIGH,
            scanner="sqli",
            title="SQL Injection",
            tool_name="query",
            parameter="sql",
        ),
        target="test"
    )
    tool = ToolInfo(name="query", description="Run SQL", parameters={"sql": "string"})

    payloads = await engine.generate_initial_payloads(state, tool)
    assert len(payloads) > 0
    # Should come from the sqli playbook
    assert any("'" in str(p.payload) or "SELECT" in str(p.payload) or "OR" in str(p.payload) for p in payloads)


@pytest.mark.asyncio
async def test_payload_engine_next_without_ai():
    """generate_next_payloads should return empty list when AI is off."""
    from mcpsec.exploit.payload_engine import PayloadEngine
    from mcpsec.exploit.state_tracker import ExploitState

    engine = PayloadEngine(use_ai=False)
    state = ExploitState(target="test")
    tool = ToolInfo(name="query", description="Run SQL")

    payloads = await engine.generate_next_payloads(state, tool, [])
    assert payloads == []


@pytest.mark.asyncio
async def test_payload_engine_verdict_without_ai():
    """render_verdict should return UNKNOWN when AI is off."""
    from mcpsec.exploit.payload_engine import PayloadEngine
    from mcpsec.exploit.state_tracker import ExploitState

    engine = PayloadEngine(use_ai=False)
    state = ExploitState(target="test")

    result = await engine.render_verdict(state, [])
    assert result["verdict"] == "UNKNOWN"
    assert "AI not available" in result["reason"]


@pytest.mark.asyncio
async def test_payload_engine_aggressive_without_ai():
    """generate_aggressive_payloads should return empty list when AI is off."""
    from mcpsec.exploit.payload_engine import PayloadEngine
    from mcpsec.exploit.state_tracker import ExploitState

    engine = PayloadEngine(use_ai=False)
    state = ExploitState(target="test")
    tool = ToolInfo(name="query", description="Run SQL")

    payloads = await engine.generate_aggressive_payloads(state, tool, [])
    assert payloads == []


@pytest.mark.asyncio
async def test_payload_engine_hinted_without_ai():
    """generate_hinted_payloads should return empty list when AI is off."""
    from mcpsec.exploit.payload_engine import PayloadEngine
    from mcpsec.exploit.state_tracker import ExploitState

    engine = PayloadEngine(use_ai=False)
    state = ExploitState(target="test")
    tool = ToolInfo(name="query", description="Run SQL")

    payloads = await engine.generate_hinted_payloads(state, tool, [], "try unicode")
    assert payloads == []


def test_format_history_empty():
    """_format_history should handle empty history."""
    from mcpsec.exploit.payload_engine import PayloadEngine

    engine = PayloadEngine(use_ai=False)
    result = engine._format_history([])
    assert result == "No prior attempts."


def test_format_history_with_entries():
    """_format_history should format history entries."""
    from mcpsec.exploit.payload_engine import PayloadEngine

    engine = PayloadEngine(use_ai=False)
    history = [
        {"payload": "' OR 1=1", "response": "Error", "manual": False},
        {"payload": "custom", "response": "OK", "manual": True},
    ]
    result = engine._format_history(history)
    assert "Attempt 1" in result
    assert "Attempt 2" in result
    assert "[MANUAL]" in result


# ─── Display suggestions test ───────────────────────────────────────────────

def test_display_suggestions_no_crash():
    """_display_suggestions should not crash with empty suggestions."""
    from mcpsec.exploit.session import ExploitSession

    try:
        session = ExploitSession(
            target="python test.py",
            transport=TransportType.STDIO,
        )
    except Exception as e:
        if "ConsoleScreenBuffer" in str(type(e).__name__) or "NoConsole" in str(e):
            pytest.skip("No console available for prompt_toolkit")
        raise

    session.current_suggestions = []
    # Should not raise
    session._display_suggestions()


# ─── REPL commands list test ────────────────────────────────────────────────

def test_repl_commands_include_new_commands():
    """COMMANDS list should include all AI exploitation commands."""
    from mcpsec.exploit.mcp_repl import COMMANDS

    for cmd in ["select", "run", "edit", "next", "verdict", "aggressive", "hint", "accept", "auto"]:
        assert cmd in COMMANDS, f"Missing command: {cmd}"
